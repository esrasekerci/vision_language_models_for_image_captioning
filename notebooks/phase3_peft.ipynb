{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PEFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-16T10:44:35.759052Z",
     "iopub.status.busy": "2025-06-16T10:44:35.758781Z",
     "iopub.status.idle": "2025-06-16T10:44:35.765504Z",
     "shell.execute_reply": "2025-06-16T10:44:35.764799Z",
     "shell.execute_reply.started": "2025-06-16T10:44:35.759027Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-06-16T10:44:37.355141Z",
     "iopub.status.busy": "2025-06-16T10:44:37.354653Z",
     "iopub.status.idle": "2025-06-16T10:46:00.280549Z",
     "shell.execute_reply": "2025-06-16T10:46:00.279865Z",
     "shell.execute_reply.started": "2025-06-16T10:44:37.355117Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 MB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m52.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install -q -U bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-16T10:46:00.282029Z",
     "iopub.status.busy": "2025-06-16T10:46:00.281755Z",
     "iopub.status.idle": "2025-06-16T10:46:12.977134Z",
     "shell.execute_reply": "2025-06-16T10:46:12.976198Z",
     "shell.execute_reply.started": "2025-06-16T10:46:00.281992Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.5/10.5 MB\u001b[0m \u001b[31m97.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m411.1/411.1 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "cesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
      "bigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\n",
      "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q -U transformers datasets peft bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-16T10:46:12.978518Z",
     "iopub.status.busy": "2025-06-16T10:46:12.978224Z",
     "iopub.status.idle": "2025-06-16T10:46:19.811367Z",
     "shell.execute_reply": "2025-06-16T10:46:19.810688Z",
     "shell.execute_reply.started": "2025-06-16T10:46:12.978464Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (1.26.4)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.31.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (25.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.18.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (19.0.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.11.18)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.13.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.1.0)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2025.1.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2022.1.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.4.26)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.20.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2022.1.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->evaluate) (1.3.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->evaluate) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->evaluate) (2024.2.0)\n",
      "Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: evaluate\n",
      "Successfully installed evaluate-0.4.3\n",
      "Collecting bert_score\n",
      "  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from bert_score) (2.6.0+cu124)\n",
      "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from bert_score) (2.2.3)\n",
      "Requirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from bert_score) (4.52.4)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from bert_score) (1.26.4)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from bert_score) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.11/dist-packages (from bert_score) (4.67.1)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from bert_score) (3.7.2)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from bert_score) (25.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert_score) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert_score) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert_score) (2025.2)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->bert_score) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->bert_score) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->bert_score) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->bert_score) (2025.1.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->bert_score) (2022.1.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->bert_score) (2.4.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (4.13.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.0.0->bert_score) (1.3.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert_score) (0.31.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert_score) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert_score) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert_score) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert_score) (0.5.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score) (1.4.8)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score) (11.1.0)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score) (3.0.9)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->bert_score) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->bert_score) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->bert_score) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->bert_score) (2025.4.26)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers>=3.0.0->bert_score) (1.1.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert_score) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.0.0->bert_score) (3.0.2)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->bert_score) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->bert_score) (2022.1.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->bert_score) (1.3.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->bert_score) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->bert_score) (2024.2.0)\n",
      "Downloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: bert_score\n",
      "Successfully installed bert_score-0.3.13\n"
     ]
    }
   ],
   "source": [
    "!pip install evaluate\n",
    "!pip install bert_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-16T10:46:19.813350Z",
     "iopub.status.busy": "2025-06-16T10:46:19.813145Z",
     "iopub.status.idle": "2025-06-16T10:46:44.423000Z",
     "shell.execute_reply": "2025-06-16T10:46:44.422403Z",
     "shell.execute_reply.started": "2025-06-16T10:46:19.813329Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-16 10:46:29.965144: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1750070790.165497      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1750070790.222848      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "from evaluate import load as hf_load\n",
    "import transformers\n",
    "import torch\n",
    "import requests\n",
    "from PIL import Image\n",
    "from transformers import AutoProcessor, PaliGemmaForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-16T10:46:44.424262Z",
     "iopub.status.busy": "2025-06-16T10:46:44.423662Z",
     "iopub.status.idle": "2025-06-16T10:46:44.559599Z",
     "shell.execute_reply": "2025-06-16T10:46:44.558986Z",
     "shell.execute_reply.started": "2025-06-16T10:46:44.424240Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "login(token = \"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\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-Tuning PaliGemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-16T10:46:44.560561Z",
     "iopub.status.busy": "2025-06-16T10:46:44.560321Z",
     "iopub.status.idle": "2025-06-16T10:47:02.560054Z",
     "shell.execute_reply": "2025-06-16T10:47:02.559516Z",
     "shell.execute_reply.started": "2025-06-16T10:46:44.560544Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mesrasekerci\u001b[0m (\u001b[33mesrasekerci-metu-middle-east-technical-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20250616_104655-jgmkpoct</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/esrasekerci-metu-middle-east-technical-university/vlm_for_image_captioning/runs/jgmkpoct' target=\"_blank\">paligemma_peft</a></strong> to <a href='https://wandb.ai/esrasekerci-metu-middle-east-technical-university/vlm_for_image_captioning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/esrasekerci-metu-middle-east-technical-university/vlm_for_image_captioning' target=\"_blank\">https://wandb.ai/esrasekerci-metu-middle-east-technical-university/vlm_for_image_captioning</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/esrasekerci-metu-middle-east-technical-university/vlm_for_image_captioning/runs/jgmkpoct' target=\"_blank\">https://wandb.ai/esrasekerci-metu-middle-east-technical-university/vlm_for_image_captioning/runs/jgmkpoct</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/esrasekerci-metu-middle-east-technical-university/vlm_for_image_captioning/runs/jgmkpoct?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7910b2d6e750>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from peft import get_peft_model, LoraConfig\n",
    "from transformers import (\n",
    "    PaliGemmaProcessor,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    EarlyStoppingCallback,\n",
    "    BitsAndBytesConfig,\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import shutil\n",
    "import os\n",
    "from evaluate import load\n",
    "import wandb\n",
    "\n",
    "# Initialize W&B\n",
    "wandb.login(key=\"0e48c15605abf65402208cd05becaa061bf0dfbf\")\n",
    "wandb.init(project=\"vlm_for_image_captioning\", name=\"paligemma_peft\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-16T10:47:02.561020Z",
     "iopub.status.busy": "2025-06-16T10:47:02.560763Z",
     "iopub.status.idle": "2025-06-16T10:47:02.565401Z",
     "shell.execute_reply": "2025-06-16T10:47:02.564738Z",
     "shell.execute_reply.started": "2025-06-16T10:47:02.560994Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data_dir = Path(\"/kaggle/input/di725-dataset\")\n",
    "image_dir = data_dir / \"resized\"\n",
    "caption_file = data_dir / \"captions.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-16T10:47:02.566595Z",
     "iopub.status.busy": "2025-06-16T10:47:02.566300Z",
     "iopub.status.idle": "2025-06-16T10:47:02.964710Z",
     "shell.execute_reply": "2025-06-16T10:47:02.964122Z",
     "shell.execute_reply.started": "2025-06-16T10:47:02.566578Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>split</th>\n",
       "      <th>image</th>\n",
       "      <th>caption_1</th>\n",
       "      <th>caption_2</th>\n",
       "      <th>caption_3</th>\n",
       "      <th>caption_4</th>\n",
       "      <th>caption_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NWPU</td>\n",
       "      <td>test</td>\n",
       "      <td>NWPU_31430.jpg</td>\n",
       "      <td>A gray plane on the runway and the lawn beside .</td>\n",
       "      <td>A grey plane is on the runway by the lawn .</td>\n",
       "      <td>There is an airplane on the runway with a larg...</td>\n",
       "      <td>A plane is parked on the runway next to the gr...</td>\n",
       "      <td>There is a plane on the runway beside the grass .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NWPU</td>\n",
       "      <td>test</td>\n",
       "      <td>NWPU_31431.jpg</td>\n",
       "      <td>Three small planes parked in a line on the air...</td>\n",
       "      <td>There are four aircraft on the open ground, Th...</td>\n",
       "      <td>There are many planes of different sizes in a ...</td>\n",
       "      <td>Four planes are parked on the runway .</td>\n",
       "      <td>Four planes of different sizes were on the mar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NWPU</td>\n",
       "      <td>test</td>\n",
       "      <td>NWPU_31432.jpg</td>\n",
       "      <td>A plane parked in a line on the airport with s...</td>\n",
       "      <td>A white plane was parked on the instruction li...</td>\n",
       "      <td>An airplane parked in an open area with many c...</td>\n",
       "      <td>A plane is parked on the open space .</td>\n",
       "      <td>There is 1 plane on the ground marked .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NWPU</td>\n",
       "      <td>test</td>\n",
       "      <td>NWPU_31433.jpg</td>\n",
       "      <td>A small plane and a big plane parked next to b...</td>\n",
       "      <td>A white plane and a gray plane parked at the b...</td>\n",
       "      <td>Two planes of different sizes are neatly parke...</td>\n",
       "      <td>A large plane and a small plane are parked nea...</td>\n",
       "      <td>Two planes are on the marked ground .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NWPU</td>\n",
       "      <td>test</td>\n",
       "      <td>NWPU_31434.jpg</td>\n",
       "      <td>Two planes parked next to boarding bridges .</td>\n",
       "      <td>Two aircraft were parked at the departure gates .</td>\n",
       "      <td>Two planes of different sizes are neatly parke...</td>\n",
       "      <td>Two planes are parked next to the terminal .</td>\n",
       "      <td>Two planes are on the marked ground .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  source split           image  \\\n",
       "0   NWPU  test  NWPU_31430.jpg   \n",
       "1   NWPU  test  NWPU_31431.jpg   \n",
       "2   NWPU  test  NWPU_31432.jpg   \n",
       "3   NWPU  test  NWPU_31433.jpg   \n",
       "4   NWPU  test  NWPU_31434.jpg   \n",
       "\n",
       "                                           caption_1  \\\n",
       "0   A gray plane on the runway and the lawn beside .   \n",
       "1  Three small planes parked in a line on the air...   \n",
       "2  A plane parked in a line on the airport with s...   \n",
       "3  A small plane and a big plane parked next to b...   \n",
       "4       Two planes parked next to boarding bridges .   \n",
       "\n",
       "                                           caption_2  \\\n",
       "0        A grey plane is on the runway by the lawn .   \n",
       "1  There are four aircraft on the open ground, Th...   \n",
       "2  A white plane was parked on the instruction li...   \n",
       "3  A white plane and a gray plane parked at the b...   \n",
       "4  Two aircraft were parked at the departure gates .   \n",
       "\n",
       "                                           caption_3  \\\n",
       "0  There is an airplane on the runway with a larg...   \n",
       "1  There are many planes of different sizes in a ...   \n",
       "2  An airplane parked in an open area with many c...   \n",
       "3  Two planes of different sizes are neatly parke...   \n",
       "4  Two planes of different sizes are neatly parke...   \n",
       "\n",
       "                                           caption_4  \\\n",
       "0  A plane is parked on the runway next to the gr...   \n",
       "1             Four planes are parked on the runway .   \n",
       "2              A plane is parked on the open space .   \n",
       "3  A large plane and a small plane are parked nea...   \n",
       "4       Two planes are parked next to the terminal .   \n",
       "\n",
       "                                           caption_5  \n",
       "0  There is a plane on the runway beside the grass .  \n",
       "1  Four planes of different sizes were on the mar...  \n",
       "2            There is 1 plane on the ground marked .  \n",
       "3              Two planes are on the marked ground .  \n",
       "4              Two planes are on the marked ground .  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(caption_file)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-16T10:47:02.965683Z",
     "iopub.status.busy": "2025-06-16T10:47:02.965418Z",
     "iopub.status.idle": "2025-06-16T10:47:03.604987Z",
     "shell.execute_reply": "2025-06-16T10:47:03.604433Z",
     "shell.execute_reply.started": "2025-06-16T10:47:02.965659Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def select_longest_caption(row):\n",
    "    captions = [row[f\"caption_{i}\"] for i in range(1, 6)]\n",
    "    longest = max(captions, key=lambda x: len(x.split()))\n",
    "    return longest\n",
    "\n",
    "df[\"caption\"] = df.apply(select_longest_caption, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-16T10:47:03.607438Z",
     "iopub.status.busy": "2025-06-16T10:47:03.607254Z",
     "iopub.status.idle": "2025-06-16T10:47:03.620739Z",
     "shell.execute_reply": "2025-06-16T10:47:03.620028Z",
     "shell.execute_reply.started": "2025-06-16T10:47:03.607423Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df.drop(columns=[f\"caption_{i}\" for i in range(1, 6)], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-16T10:47:03.621846Z",
     "iopub.status.busy": "2025-06-16T10:47:03.621555Z",
     "iopub.status.idle": "2025-06-16T10:47:03.638218Z",
     "shell.execute_reply": "2025-06-16T10:47:03.637653Z",
     "shell.execute_reply.started": "2025-06-16T10:47:03.621828Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>split</th>\n",
       "      <th>image</th>\n",
       "      <th>caption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NWPU</td>\n",
       "      <td>test</td>\n",
       "      <td>NWPU_31430.jpg</td>\n",
       "      <td>There is an airplane on the runway with a larg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NWPU</td>\n",
       "      <td>test</td>\n",
       "      <td>NWPU_31431.jpg</td>\n",
       "      <td>There are four aircraft on the open ground, Th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NWPU</td>\n",
       "      <td>test</td>\n",
       "      <td>NWPU_31432.jpg</td>\n",
       "      <td>An airplane parked in an open area with many c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NWPU</td>\n",
       "      <td>test</td>\n",
       "      <td>NWPU_31433.jpg</td>\n",
       "      <td>A white plane and a gray plane parked at the b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NWPU</td>\n",
       "      <td>test</td>\n",
       "      <td>NWPU_31434.jpg</td>\n",
       "      <td>Two planes of different sizes are neatly parke...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  source split           image  \\\n",
       "0   NWPU  test  NWPU_31430.jpg   \n",
       "1   NWPU  test  NWPU_31431.jpg   \n",
       "2   NWPU  test  NWPU_31432.jpg   \n",
       "3   NWPU  test  NWPU_31433.jpg   \n",
       "4   NWPU  test  NWPU_31434.jpg   \n",
       "\n",
       "                                             caption  \n",
       "0  There is an airplane on the runway with a larg...  \n",
       "1  There are four aircraft on the open ground, Th...  \n",
       "2  An airplane parked in an open area with many c...  \n",
       "3  A white plane and a gray plane parked at the b...  \n",
       "4  Two planes of different sizes are neatly parke...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-16T10:47:03.639255Z",
     "iopub.status.busy": "2025-06-16T10:47:03.639008Z",
     "iopub.status.idle": "2025-06-16T10:47:03.664449Z",
     "shell.execute_reply": "2025-06-16T10:47:03.663650Z",
     "shell.execute_reply.started": "2025-06-16T10:47:03.639232Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Count  Percentage\n",
      "split                   \n",
      "train  35614       79.99\n",
      "test    4454       10.00\n",
      "val     4453       10.00\n"
     ]
    }
   ],
   "source": [
    "split_counts = df[\"split\"].value_counts()\n",
    "split_percent = df[\"split\"].value_counts(normalize=True) * 100\n",
    "\n",
    "split_info = pd.DataFrame({\n",
    "    \"Count\": split_counts,\n",
    "    \"Percentage\": split_percent.round(2)\n",
    "})\n",
    "\n",
    "print(split_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-16T10:47:03.665662Z",
     "iopub.status.busy": "2025-06-16T10:47:03.665300Z",
     "iopub.status.idle": "2025-06-16T10:47:03.697141Z",
     "shell.execute_reply": "2025-06-16T10:47:03.696416Z",
     "shell.execute_reply.started": "2025-06-16T10:47:03.665635Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Split\n",
    "train_df = df[df[\"split\"] == \"train\"].copy()\n",
    "val_df = df[df[\"split\"] == \"val\"].copy()\n",
    "test_df = df[df[\"split\"] == \"test\"].copy()\n",
    "\n",
    "# Drop unnecessary columns\n",
    "train_df = train_df[[\"image\", \"caption\"]].reset_index(drop=True)\n",
    "val_df = val_df[[\"image\", \"caption\"]].reset_index(drop=True)\n",
    "test_df = test_df[[\"image\", \"caption\"]].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-16T10:47:03.698153Z",
     "iopub.status.busy": "2025-06-16T10:47:03.697911Z",
     "iopub.status.idle": "2025-06-16T10:47:03.706257Z",
     "shell.execute_reply": "2025-06-16T10:47:03.705715Z",
     "shell.execute_reply.started": "2025-06-16T10:47:03.698132Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>caption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RSICD_0.jpg</td>\n",
       "      <td>many planes are parked next to a long building...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RSICD_1.jpg</td>\n",
       "      <td>the airport here is full of airplanes and cont...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RSICD_2.jpg</td>\n",
       "      <td>many planes are parked in an airport near many...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RSICD_3.jpg</td>\n",
       "      <td>many planes are parked near a large building o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RSICD_4.jpg</td>\n",
       "      <td>several buildings and green trees are around a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35609</th>\n",
       "      <td>UCM_2075.jpg</td>\n",
       "      <td>There is a small tennis court and surrounded b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35610</th>\n",
       "      <td>UCM_2076.jpg</td>\n",
       "      <td>There are two tennis courts surrounded by some...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35611</th>\n",
       "      <td>UCM_2077.jpg</td>\n",
       "      <td>There is a small tennis court and surrounded b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35612</th>\n",
       "      <td>UCM_2078.jpg</td>\n",
       "      <td>There is a tennis court surrounded by some car...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35613</th>\n",
       "      <td>UCM_2079.jpg</td>\n",
       "      <td>There is a tennis court surrounded by some car...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35614 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              image                                            caption\n",
       "0       RSICD_0.jpg  many planes are parked next to a long building...\n",
       "1       RSICD_1.jpg  the airport here is full of airplanes and cont...\n",
       "2       RSICD_2.jpg  many planes are parked in an airport near many...\n",
       "3       RSICD_3.jpg  many planes are parked near a large building o...\n",
       "4       RSICD_4.jpg  several buildings and green trees are around a...\n",
       "...             ...                                                ...\n",
       "35609  UCM_2075.jpg  There is a small tennis court and surrounded b...\n",
       "35610  UCM_2076.jpg  There are two tennis courts surrounded by some...\n",
       "35611  UCM_2077.jpg  There is a small tennis court and surrounded b...\n",
       "35612  UCM_2078.jpg  There is a tennis court surrounded by some car...\n",
       "35613  UCM_2079.jpg  There is a tennis court surrounded by some car...\n",
       "\n",
       "[35614 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-16T13:44:42.693487Z",
     "iopub.status.busy": "2025-06-16T13:44:42.692942Z",
     "iopub.status.idle": "2025-06-16T13:44:43.367755Z",
     "shell.execute_reply": "2025-06-16T13:44:43.367217Z",
     "shell.execute_reply.started": "2025-06-16T13:44:42.693442Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import gc, torch\n",
    "gc.collect()\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-16T09:20:07.054933Z",
     "iopub.status.busy": "2025-06-16T09:20:07.054401Z",
     "iopub.status.idle": "2025-06-16T09:20:07.064044Z",
     "shell.execute_reply": "2025-06-16T09:20:07.063272Z",
     "shell.execute_reply.started": "2025-06-16T09:20:07.054906Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Dataset Class\n",
    "class ImageCaptionDataset(Dataset):\n",
    "    def __init__(self, dataframe, image_dir):\n",
    "        self.df = dataframe.reset_index(drop=True)\n",
    "        self.image_dir = Path(image_dir)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        image_path = self.image_dir / row[\"image\"]\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        return {\"image\": image, \"caption\": row[\"caption\"]}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "# Create Datasets\n",
    "train_ds = ImageCaptionDataset(train_df, image_dir)\n",
    "val_ds = ImageCaptionDataset(val_df, image_dir)\n",
    "test_ds = ImageCaptionDataset(test_df, image_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-15T09:15:14.579791Z",
     "iopub.status.busy": "2025-06-15T09:15:14.579533Z",
     "iopub.status.idle": "2025-06-15T09:18:47.045633Z",
     "shell.execute_reply": "2025-06-15T09:18:47.044874Z",
     "shell.execute_reply.started": "2025-06-15T09:15:14.579750Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04fbfbe6a71441da9bdd8c073ed6a5a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/699 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75c61cc9ee394347b120be6e4458256d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/40.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2633462cfa2f4ec680f55b7c0851610e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/4.26M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb0d2ac7256b49f7808182ea362b9aed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c2de759667447c684ff965e5c4a91e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/24.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "776984bd5498495cb67139b5b1d86903",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/607 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1153aca510004e2ebb7666e1c848cf3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.03k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc066128ac0d49b2b175c4ef6a536693",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/62.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31add7671e9b4a86a7c4b0f51b7d4bd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ae0d128ab1244fcb488e17ba18075c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00003.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eef74ea20f52412386da078ceed1c2dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00003.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "491d706847674f468116c4ff5f834fcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00003.safetensors:   0%|          | 0.00/1.74G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94734ef6bdb34c05a062a0a3ecdb4651",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb5d94ce18214a78b42f352778d88574",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/137 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "081b7b29466541db8c07b8a2beacca1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 11,298,816 || all params: 2,934,765,296 || trainable%: 0.3850\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c715fb23b9d45a284310c88716b1549",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/5.94k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc2d0cb0d9964ae6883c85eaec87a0d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading extra modules:   0%|          | 0.00/1.55k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6bc63662acd4099b453d4b909179203",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading extra modules:   0%|          | 0.00/3.34k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "623bfc78c7ba495689b63762144627ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/7.02k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /usr/share/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /usr/share/nltk_data...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3eac77b4b5947fc84260b417a2ae32d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/7.95k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    }
   ],
   "source": [
    "# Processor and Prompt Template\n",
    "model_id = \"google/paligemma-3b-pt-224\"\n",
    "device = \"cuda\"\n",
    "processor = PaliGemmaProcessor.from_pretrained(model_id)\n",
    "prompt_template = \"<image> explain the layout of the terrain and infrastructure.\"\n",
    "\n",
    "# Collate Function\n",
    "def collate_fn(examples):\n",
    "    prompt = \"<image> explain the layout of the terrain and infrastructure.\"\n",
    "    captions = [ex[\"caption\"] for ex in examples]\n",
    "    images = [ex[\"image\"] for ex in examples]\n",
    "    text_with_targets = [f\"{prompt} {caption}\" for caption in captions]\n",
    "\n",
    "    tokens = processor(\n",
    "        text=text_with_targets,\n",
    "        images=images,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=\"longest\"\n",
    "    )\n",
    "\n",
    "    # Set input_ids as labels (for causal language modeling)\n",
    "    tokens[\"labels\"] = tokens[\"input_ids\"].clone()\n",
    "\n",
    "    # Move tensors to device\n",
    "    for k, v in tokens.items():\n",
    "        if isinstance(v, torch.Tensor):\n",
    "            if v.dtype in [torch.float32, torch.float64]:\n",
    "                tokens[k] = v.to(device, dtype=torch.bfloat16)\n",
    "            else:\n",
    "                tokens[k] = v.to(device)\n",
    "    return tokens\n",
    "\n",
    "model = PaliGemmaForConditionalGeneration.from_pretrained(model_id, torch_dtype=torch.bfloat16).to(device)\n",
    "for param in model.vision_tower.parameters():\n",
    "      param.requires_grad = False\n",
    "for param in model.multi_modal_projector.parameters():\n",
    "      param.requires_grad = False\n",
    "    \n",
    "# Quantization + LoRA Config\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    target_modules=[\"q_proj\", \"o_proj\", \"k_proj\", \"v_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "\n",
    "# Load Model with Quantization + LoRA\n",
    "model = PaliGemmaForConditionalGeneration.from_pretrained(model_id, quantization_config=bnb_config, device_map={\"\":0})\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()\n",
    "\n",
    "# Evaluation Metrics\n",
    "bleu = load(\"bleu\")\n",
    "meteor = load(\"meteor\")\n",
    "bertscore = load(\"bertscore\")\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    predictions, labels = eval_preds\n",
    "    decoded_preds = processor.batch_decode(predictions, skip_special_tokens=True)\n",
    "    decoded_labels = processor.batch_decode(labels, skip_special_tokens=True)\n",
    "    return {\n",
    "        \"bleu\": bleu.compute(predictions=decoded_preds, references=[[l] for l in decoded_labels])[\"bleu\"],\n",
    "        \"meteor\": meteor.compute(predictions=decoded_preds, references=decoded_labels)[\"meteor\"],\n",
    "        \"bertscore_f1\": bertscore.compute(predictions=decoded_preds, references=decoded_labels, lang=\"en\")[\"f1\"]\n",
    "    }\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"finetuned_paligemma\",\n",
    "    max_steps=1000,\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=2,\n",
    "    gradient_accumulation_steps=4,\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=1e-6,\n",
    "    warmup_steps=2,\n",
    "    adam_beta2=0.999,\n",
    "    logging_steps=10,\n",
    "    optim=\"adamw_8bit\",\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=100,\n",
    "    save_total_limit=1,\n",
    "    bf16=True,\n",
    "    dataloader_pin_memory=False,\n",
    "    report_to=[\"wandb\"],\n",
    "    remove_unused_columns=False\n",
    ")\n",
    "\n",
    "# Trainer Setup\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=val_ds,\n",
    "    data_collator=collate_fn,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-15T09:18:47.046626Z",
     "iopub.status.busy": "2025-06-15T09:18:47.046410Z",
     "iopub.status.idle": "2025-06-15T11:34:12.574800Z",
     "shell.execute_reply": "2025-06-15T11:34:12.574196Z",
     "shell.execute_reply.started": "2025-06-15T09:18:47.046610Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1000/1000 2:15:15, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>18.547900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>18.098500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>17.411500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>16.662300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>16.060000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>15.344400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>14.778100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>14.252000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>13.792500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>13.377400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>13.122300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>12.983500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>12.749900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>12.604300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>12.450900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>12.392500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>12.232900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>12.190700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>12.139400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>12.162500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>12.072500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>12.043900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>12.023800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>11.958800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>11.945300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>11.966100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>11.922100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>11.969500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>11.882600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>11.861100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>11.964400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>11.906800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>11.871500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>11.787400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>11.771400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>11.857800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>11.814400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>11.826400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>11.841200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>11.797300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>11.763000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>11.799200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>11.770100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>11.783000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>11.740400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>11.728900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>11.786300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>11.764800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>11.681700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>11.751700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>11.730000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>11.723600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>11.729800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>11.731700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>11.764500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>11.736900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>11.751900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>11.742200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>11.752400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>11.789100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>11.700100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>11.780000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>11.769600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>11.766900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>11.704100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>11.759300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>11.750400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>11.722100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>11.728500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>11.773400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>11.768000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>11.736900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>11.759000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>11.768300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>11.756400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>11.753200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>11.727000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>11.734900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>11.745900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>11.786000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>11.774600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>11.785800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>11.690600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>11.785100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>11.760200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>11.704700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>11.752300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>11.740800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>11.749400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>11.764200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910</td>\n",
       "      <td>11.743500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>11.723000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930</td>\n",
       "      <td>11.763300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>11.793800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>11.760700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>11.759700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>970</td>\n",
       "      <td>11.727300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>11.724700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>990</td>\n",
       "      <td>11.724400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>11.766100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1000, training_loss=12.26443236541748, metrics={'train_runtime': 8124.704, 'train_samples_per_second': 0.985, 'train_steps_per_second': 0.123, 'total_flos': 3.3232563912330624e+16, 'train_loss': 12.26443236541748, 'epoch': 0.22463076318301792})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-15T11:34:12.575768Z",
     "iopub.status.busy": "2025-06-15T11:34:12.575524Z",
     "iopub.status.idle": "2025-06-15T11:34:19.408361Z",
     "shell.execute_reply": "2025-06-15T11:34:19.407710Z",
     "shell.execute_reply.started": "2025-06-15T11:34:12.575729Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete. Model and processor saved and zipped for download.\n"
     ]
    }
   ],
   "source": [
    "# Define save path\n",
    "save_path = \"finetuned_paligemma_riscm_final\"\n",
    "\n",
    "# Save model and processor\n",
    "model.save_pretrained(save_path)\n",
    "processor.save_pretrained(save_path)\n",
    "\n",
    "# Create a zip archive\n",
    "shutil.make_archive(\"paligemma_riscm_model\", \"zip\", save_path)\n",
    "\n",
    "print(\"Training complete. Model and processor saved and zipped for download.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-16T05:30:53.449657Z",
     "iopub.status.busy": "2025-06-16T05:30:53.449281Z",
     "iopub.status.idle": "2025-06-16T07:56:20.675459Z",
     "shell.execute_reply": "2025-06-16T07:56:20.674747Z",
     "shell.execute_reply.started": "2025-06-16T05:30:53.449631Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1114/1114 [2:24:51<00:00,  7.80s/it] \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97af659286624b5b91455bceeed05f35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76e1e7d809c948f9923a666f972a3e0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "feb3332f689e4a92b421d43e3bf600b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75823066a17145048b20120686434c0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f63562696dc47ad98186580c1804c91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41a79d8694174b1c96aaec754f68f9bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Evaluation Results:\n",
      "BLEU: 0.0000\n",
      "METEOR: 0.1036\n",
      "BERTScore_F1: 0.8197\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "BATCH_SIZE = 4  # or 2/8, depending on your GPU\n",
    "model.eval()\n",
    "generated_ids_list = []\n",
    "references = []\n",
    "\n",
    "for i in tqdm(range(0, len(test_ds), BATCH_SIZE)):\n",
    "    batch = [test_ds[j] for j in range(i, min(i+BATCH_SIZE, len(test_ds)))]\n",
    "    images = [x[\"image\"] for x in batch]\n",
    "    captions = [x[\"caption\"] for x in batch]\n",
    "    inputs = processor(\n",
    "        text=[\"<image> explain the layout of the terrain and infrastructure.\"]*len(images),\n",
    "        images=images,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=\"longest\"\n",
    "    )\n",
    "    for k, v in inputs.items():\n",
    "        inputs[k] = v.to(model.device)\n",
    "    with torch.no_grad(), torch.autocast(\"cuda\", dtype=torch.bfloat16):\n",
    "        output_ids = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=30,\n",
    "            do_sample=False,       # greedy\n",
    "            num_beams=1,\n",
    "            eos_token_id=processor.tokenizer.eos_token_id\n",
    "        )\n",
    "    decoded_batch = processor.tokenizer.batch_decode(output_ids, skip_special_tokens=True)\n",
    "    prompt = \"<image> explain the layout of the terrain and infrastructure.\"\n",
    "    decoded_batch = [d[len(prompt):].strip() if d.startswith(prompt) else d for d in decoded_batch]\n",
    "    generated_ids_list.extend(decoded_batch)\n",
    "    references.extend(captions)\n",
    "    if i % 200 == 0:\n",
    "        torch.cuda.empty_cache()\n",
    "        import gc; gc.collect()\n",
    "\n",
    "results = {\n",
    "    \"BLEU\": bleu.compute(predictions=generated_ids_list, references=[[ref] for ref in references])[\"bleu\"],\n",
    "    \"METEOR\": meteor.compute(predictions=generated_ids_list, references=references)[\"meteor\"],\n",
    "    \"BERTScore_F1\": sum(bertscore.compute(predictions=generated_ids_list, references=references, lang=\"en\")[\"f1\"]) / len(generated_ids_list)\n",
    "}\n",
    "\n",
    "print(\"Test Set Evaluation Results:\")\n",
    "for metric, value in results.items():\n",
    "    print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    \"reference_caption\": references,\n",
    "    \"generated_caption\": generated_ids_list,\n",
    "})\n",
    "results_df.to_csv(\"test_results.csv\", index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-16T08:17:50.103317Z",
     "iopub.status.busy": "2025-06-16T08:17:50.102691Z",
     "iopub.status.idle": "2025-06-16T08:17:53.202530Z",
     "shell.execute_reply": "2025-06-16T08:17:53.201715Z",
     "shell.execute_reply.started": "2025-06-16T08:17:50.103295Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference Caption: There is a plane on the runway and three planes in the open space next to the runway .\n",
      "Generated Caption:  explain the layout of the terrain and infrastructure.\n",
      " explain the layout of the terrain and infrastructure.\n",
      " explain the layout of the terrain and infrastructure.\n",
      " explain the layout of the terrain and infrastructure.\n",
      " explain the layout of the terrain\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "prompt = \"<image> explain the layout of the terrain and infrastructure.\"\n",
    "example = test_ds[15]\n",
    "image = example[\"image\"]\n",
    "caption = example[\"caption\"]\n",
    "\n",
    "# Preprocess (this always returns tensors on CPU)\n",
    "inputs = processor(\n",
    "    image,\n",
    "    prompt,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "# Move to CUDA: only cast pixel_values to bfloat16!\n",
    "for k, v in inputs.items():\n",
    "    if k == \"pixel_values\":\n",
    "        inputs[k] = v.to(\"cuda\", dtype=torch.bfloat16)\n",
    "    else:\n",
    "        inputs[k] = v.to(\"cuda\")\n",
    "\n",
    "# Generate\n",
    "with torch.no_grad():\n",
    "    generated_ids = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=40\n",
    "    )\n",
    "\n",
    "# Decode\n",
    "decoded_caption = processor.decode(generated_ids[0], skip_special_tokens=True)\n",
    "if decoded_caption.startswith(prompt):\n",
    "    decoded_caption = decoded_caption[len(prompt):].strip()\n",
    "\n",
    "print(\"Reference Caption:\", caption)\n",
    "print(\"Generated Caption:\", decoded_caption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-16T10:48:40.590562Z",
     "iopub.status.busy": "2025-06-16T10:48:40.590260Z",
     "iopub.status.idle": "2025-06-16T10:48:40.595292Z",
     "shell.execute_reply": "2025-06-16T10:48:40.594648Z",
     "shell.execute_reply.started": "2025-06-16T10:48:40.590542Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import builtins\n",
    "builtins.np = np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-16T10:47:40.399441Z",
     "iopub.status.busy": "2025-06-16T10:47:40.398671Z",
     "iopub.status.idle": "2025-06-16T10:47:40.404657Z",
     "shell.execute_reply": "2025-06-16T10:47:40.403919Z",
     "shell.execute_reply.started": "2025-06-16T10:47:40.399416Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.52.4\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-16T11:03:11.580891Z",
     "iopub.status.busy": "2025-06-16T11:03:11.580137Z",
     "iopub.status.idle": "2025-06-16T11:20:35.652739Z",
     "shell.execute_reply": "2025-06-16T11:20:35.652145Z",
     "shell.execute_reply.started": "2025-06-16T11:03:11.580854Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1a8f50e14084525971bf331af638799",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [500/500 17:07, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.798800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>2.539800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>3.232600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>2.433900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.306200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.948000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>2.157100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>2.216100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>2.145400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.926900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>2.024300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1.894000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>2.050100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>2.031300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.548300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1.713300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>1.708100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>1.564100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>1.768400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.730000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>1.636900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>1.396100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>1.766300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>1.560300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.265800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# --- Dataset class ---\n",
    "class ImageCaptionDataset(Dataset):\n",
    "    def __init__(self, dataframe, image_dir):\n",
    "        self.df = dataframe.reset_index(drop=True)\n",
    "        self.image_dir = image_dir\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        image_path = str(self.image_dir / row[\"image\"])\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        return {\"image\": image, \"caption\": row[\"caption\"]}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "train_ds = ImageCaptionDataset(train_df, image_dir)\n",
    "val_ds = ImageCaptionDataset(val_df, image_dir)\n",
    "test_ds = ImageCaptionDataset(test_df, image_dir)\n",
    "\n",
    "# --- Initialize processor/model/args ---\n",
    "model_id = \"google/paligemma-3b-pt-224\"\n",
    "device = \"cuda\"\n",
    "processor = PaliGemmaProcessor.from_pretrained(model_id)\n",
    "prompt = \"<image> explain the layout of the terrain and infrastructure.\"\n",
    "\n",
    "def collate_fn(examples):\n",
    "    texts = [prompt for _ in examples]                   # This is the *input* prompt\n",
    "    labels = [ex[\"caption\"] for ex in examples]          # This is the *target* (caption only)\n",
    "    images = [ex[\"image\"].convert(\"RGB\") for ex in examples]\n",
    "    tokens = processor(\n",
    "        text=texts,\n",
    "        images=images,\n",
    "        suffix=labels,             # <--- This will mask the prompt portion\n",
    "        return_tensors=\"pt\",\n",
    "        padding=\"longest\"\n",
    "    )\n",
    "    tokens = {k: v.to(device) if isinstance(v, torch.Tensor) else v for k, v in tokens.items()}\n",
    "    #print(processor.tokenizer.decode([t for t in tokens[\"labels\"][0] if t != -100]))\n",
    "\n",
    "    return tokens\n",
    "\n",
    "# --- LoRA & quantization config ---\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    target_modules=[\"q_proj\", \"o_proj\", \"k_proj\", \"v_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "\n",
    "model = PaliGemmaForConditionalGeneration.from_pretrained(\n",
    "    model_id, quantization_config=bnb_config, device_map={\"\": 0}\n",
    ")\n",
    "for param in model.vision_tower.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model.multi_modal_projector.parameters():\n",
    "    param.requires_grad = False\n",
    "model = get_peft_model(model, lora_config)\n",
    "\n",
    "# --- TrainingArguments ---\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"finetuned_paligemma\",\n",
    "    per_device_train_batch_size=2,\n",
    "    learning_rate=2e-3,\n",
    "    num_train_epochs=1,\n",
    "    max_steps=500,\n",
    "    logging_steps=20,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=100,\n",
    "    save_total_limit=2,\n",
    "    report_to=[\"wandb\"],\n",
    "    bf16=True,\n",
    "    dataloader_pin_memory=False,\n",
    "    remove_unused_columns=False,\n",
    ")\n",
    "\n",
    "# --- Trainer setup ---\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=val_ds,\n",
    "    data_collator=collate_fn,\n",
    ")\n",
    "trainer.train()\n",
    "\n",
    "# ---- Save ONLY the LoRA adapter (PEFT) ----\n",
    "model.save_pretrained(\"finetuned_paligemma_lora\")\n",
    "processor.save_pretrained(\"finetuned_paligemma_lora\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-16T11:29:32.551128Z",
     "iopub.status.busy": "2025-06-16T11:29:32.550842Z",
     "iopub.status.idle": "2025-06-16T11:29:33.970347Z",
     "shell.execute_reply": "2025-06-16T11:29:33.969536Z",
     "shell.execute_reply.started": "2025-06-16T11:29:32.551108Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using PaliGemma without a text prefix. It will perform as a picture-captioning model.\n",
      "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference: There is a plane on the runway and three planes in the open space next to the runway .\n",
      "Generated: There are several planes parked on the lawn next to the runway .\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "example = test_ds[15]\n",
    "\n",
    "# --- Do NOT include the prompt in inference! ---\n",
    "inputs = processor(\n",
    "    images=example[\"image\"].convert(\"RGB\"),\n",
    "    return_tensors=\"pt\"\n",
    ").to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    output_ids = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=30,\n",
    "        do_sample=False,\n",
    "        eos_token_id=processor.tokenizer.eos_token_id,\n",
    "        pad_token_id=processor.tokenizer.pad_token_id\n",
    "    )\n",
    "\n",
    "generated_caption = processor.decode(output_ids[0], skip_special_tokens=True).strip()\n",
    "\n",
    "print(\"Reference:\", example[\"caption\"])\n",
    "print(\"Generated:\", generated_caption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-16T11:31:32.128686Z",
     "iopub.status.busy": "2025-06-16T11:31:32.128074Z",
     "iopub.status.idle": "2025-06-16T11:31:35.069062Z",
     "shell.execute_reply": "2025-06-16T11:31:35.068494Z",
     "shell.execute_reply.started": "2025-06-16T11:31:32.128663Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the LoRA adapter\n",
    "model.save_pretrained(\"finetuned_paligemma_lora\")\n",
    "\n",
    "# Save the processor (tokenizer/image transforms)\n",
    "processor.save_pretrained(\"finetuned_paligemma_lora\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-16T11:31:42.954833Z",
     "iopub.status.busy": "2025-06-16T11:31:42.954086Z",
     "iopub.status.idle": "2025-06-16T11:31:46.380899Z",
     "shell.execute_reply": "2025-06-16T11:31:46.380330Z",
     "shell.execute_reply.started": "2025-06-16T11:31:42.954807Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/kaggle/working/finetuned_paligemma_lora.zip'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "shutil.make_archive('finetuned_paligemma_lora', 'zip', 'finetuned_paligemma_lora')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "model.eval()\n",
    "generated_captions = []\n",
    "references = []\n",
    "\n",
    "for i in tqdm(range(len(test_ds)), desc=\"Generating captions\", ncols=100):\n",
    "    example = test_ds[i]\n",
    "    inputs = processor(\n",
    "        text=\"<image>\",  # Always provide <image> token as text!\n",
    "        images=example[\"image\"].convert(\"RGB\"),\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(device)\n",
    "    with torch.no_grad():\n",
    "        output_ids = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=30,\n",
    "            do_sample=False,\n",
    "            eos_token_id=processor.tokenizer.eos_token_id,\n",
    "            pad_token_id=processor.tokenizer.pad_token_id\n",
    "        )\n",
    "    gen_caption = processor.decode(output_ids[0], skip_special_tokens=True).strip()\n",
    "    generated_captions.append(gen_caption)\n",
    "    references.append(example[\"caption\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-16T13:42:48.846363Z",
     "iopub.status.busy": "2025-06-16T13:42:48.846084Z",
     "iopub.status.idle": "2025-06-16T13:43:17.053633Z",
     "shell.execute_reply": "2025-06-16T13:43:17.052795Z",
     "shell.execute_reply.started": "2025-06-16T13:42:48.846343Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7034d3dc04e49f781bb747bfa0c25d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/7.02k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /usr/share/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /usr/share/nltk_data...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ea5016f691c4498a059a7517a7b77d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/7.95k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdfff80e701941bf93b37c202befe3d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8eae67533c934b80ab79fddd8ba7e2bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a860951e5190414c8d2075edda50c9e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11e648fd6535431ebc01f51d12fcbc02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f2b17d3da2245bb83e747ea156c1d9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ff201a4921d44b1a28df47174356a7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Evaluation Results:\n",
      "BLEU: 0.2047\n",
      "METEOR: 0.3981\n",
      "BERTScore_F1: 0.9134\n"
     ]
    }
   ],
   "source": [
    "bleu = evaluate.load(\"bleu\")\n",
    "meteor = evaluate.load(\"meteor\")\n",
    "bertscore = evaluate.load(\"bertscore\")\n",
    "\n",
    "results = {\n",
    "    \"BLEU\": bleu.compute(predictions=generated_captions, references=[[ref] for ref in references])[\"bleu\"],\n",
    "    \"METEOR\": meteor.compute(predictions=generated_captions, references=references)[\"meteor\"],\n",
    "    \"BERTScore_F1\": sum(bertscore.compute(predictions=generated_captions, references=references, lang=\"en\")[\"f1\"]) / len(generated_captions)\n",
    "}\n",
    "\n",
    "print(\"Test Set Evaluation Results:\")\n",
    "for metric, value in results.items():\n",
    "    print(f\"{metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-16T13:43:17.055611Z",
     "iopub.status.busy": "2025-06-16T13:43:17.054883Z",
     "iopub.status.idle": "2025-06-16T13:43:17.060848Z",
     "shell.execute_reply": "2025-06-16T13:43:17.059955Z",
     "shell.execute_reply.started": "2025-06-16T13:43:17.055588Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BLEU': 0.20473257594288874,\n",
       " 'METEOR': 0.39805607056565906,\n",
       " 'BERTScore_F1': 0.9134168090791407}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-16T13:40:21.667878Z",
     "iopub.status.busy": "2025-06-16T13:40:21.667096Z",
     "iopub.status.idle": "2025-06-16T13:40:21.786529Z",
     "shell.execute_reply": "2025-06-16T13:40:21.785776Z",
     "shell.execute_reply.started": "2025-06-16T13:40:21.667852Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame({\n",
    "    \"image\": [test_ds.df.iloc[i][\"image\"] for i in range(len(generated_captions))],\n",
    "    \"reference_caption\": references,\n",
    "    \"generated_caption\": generated_captions\n",
    "})\n",
    "\n",
    "results_df.to_csv(\"test_peft_results.csv\", index=False, encoding=\"utf-8\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7400913,
     "sourceId": 11787164,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7669272,
     "sourceId": 12177206,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
